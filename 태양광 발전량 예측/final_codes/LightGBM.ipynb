{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DACON(태양광)_LightGBM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEuz8b1wPVva"
      },
      "source": [
        "# 1. Data & Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj3oDlRposLf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8e2790eb-214a-486a-fca0-ff0a9ca05e18"
      },
      "source": [
        "!pip install bayesian-optimization\r\n",
        "!pip install chart-studio\r\n",
        "\r\n",
        "# 연산\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# 기타\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "# 계층적 샘플링\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.utils.multiclass import type_of_target\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "\r\n",
        "# visualization\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import chart_studio.plotly as py\r\n",
        "import cufflinks as cf\r\n",
        "cf.go_offline(connected=True)\r\n",
        "import plotly\r\n",
        "import plotly.express as px\r\n",
        "import plotly.graph_objs as go\r\n",
        "import plotly.figure_factory as ff\r\n",
        "from plotly.offline import iplot, init_notebook_mode\r\n",
        "plotly.io.renderers.default = 'colab' # colab에서 plotly가 돌아가기 위해\r\n",
        "\r\n",
        "# 모델링\r\n",
        "from lightgbm import LGBMRegressor\r\n",
        "from bayes_opt import BayesianOptimization\r\n",
        "import lightgbm as lgb\r\n",
        "\r\n",
        "# 랜덤 시드 고정\r\n",
        "random_seed = 42"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Requirement already satisfied: chart-studio in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU6UPvUrPjh6",
        "outputId": "0fa62d8f-b913-4370-f52c-da2012853bca"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/DACON/태양광/재구조화/train_재구조화')\r\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/DACON/태양광/재구조화/test_재구조화')\r\n",
        "print(f'train shape: {train_df.shape} \\ntest shape:  {test_df.shape}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (52176, 192) \n",
            "test shape:  (3888, 190)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gttxmF1XdGm"
      },
      "source": [
        "# 2. Stratified Sampling \r\n",
        "\r\n",
        "* submission 제출 시에는 TARGET 1,2에 대해서 모두 계층적 샘플링을 진행\r\n",
        "* 중복되는 부분을 제외하기 위해 편의상 TARGET 1에 대해서만 코드가 존재"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezs6ZvZgxFWf"
      },
      "source": [
        "## TARGET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIxhwqYzyWS8"
      },
      "source": [
        "random_seed = 42"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUoP0uhGpeRW",
        "outputId": "57cbad3f-3fe8-4ae3-8862-ff14eb3998f0"
      },
      "source": [
        "# TARGET을 기준으로 계층적 샘플링을 하기 위해\r\n",
        "def target_scaler(x):\r\n",
        "  for i in range(200):\r\n",
        "    if (x>i) & (x<=i+1):\r\n",
        "      return i\r\n",
        "    elif x==0:\r\n",
        "      return 0\r\n",
        "\r\n",
        "train_df['TARGET_day7_cata']=train_df['TARGET_day7'].apply(target_scaler)\r\n",
        "# train_df['TARGET_day7_cata'].unique()\r\n",
        "# array([ 0,  7, 15, 23, 30, 36, 41, 45, 48, 49, 47, 43, 39, 33, 26, 19, 10,\r\n",
        "#        3,  8, 12, 17, 20, 28, 29, 44, 11,  4, 16, 25, 37, 38,  1,  5,  6,\r\n",
        "#       14, 40, 32,  9,  2, 27, 22, 35, 34, 18, 13, 24, 31, 50, 51, 46, 21,\r\n",
        "#       52, 42, 53, 55, 56, 54, 57, 59, 58, 60, 61, 62, 64, 63, 67, 68, 66,\r\n",
        "#       65, 69, 71, 70, 72, 75, 76, 74, 77, 78, 73, 80, 79, 82, 83, 81, 85,\r\n",
        "#       86, 84, 90, 91, 88, 89, 87, 92, 93, 94, 95, 96, 97, 98, 99])\r\n",
        "\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "train_df.TARGET_day7_cata = label_encoder.fit_transform(train_df.TARGET_day7_cata)\r\n",
        "print(type_of_target(train_df.TARGET_day7_cata)) # type 확인\r\n",
        "\r\n",
        "# 연도별 앙상블을 위해 3년 데이터를 3분할\r\n",
        "train_df1=train_df.iloc[:48*365,:]\r\n",
        "train_df2=train_df.iloc[48*365:365*48*2,:]\r\n",
        "train_df3=train_df.iloc[365*48*2:,:]\r\n",
        "\r\n",
        "stf=StratifiedKFold(n_splits=5, shuffle=False, random_state=random_seed)\r\n",
        "\r\n",
        "#마지막 fold를 사용, 사실 모든 fold를 활용해야 하지만 Bayesian Optimization과 LightGBM으로 qunatile loss를 metric으로 kFold를 구현하지 못해서 마지막 fold만 이용\r\n",
        "for train_index1,valid_index1 in stf.split(train_df1, train_df1.TARGET_day7_cata):\r\n",
        "  print(train_index1, valid_index1)\r\n",
        "\r\n",
        "for train_index2,valid_index2 in stf.split(train_df2, train_df2.TARGET_day7_cata):\r\n",
        "  print(train_index2, valid_index2)\r\n",
        "\r\n",
        "for train_index3,valid_index3 in stf.split(train_df3, train_df3.TARGET_day7_cata):\r\n",
        "  print(train_index3, valid_index3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multiclass\n",
            "[ 1997  2084  2089 ... 17517 17518 17519] [   0    1    2 ... 7077 7514 7558]\n",
            "[    0     1     2 ... 17517 17518 17519] [1997 2084 2089 ... 8707 8769 9055]\n",
            "[    0     1     2 ... 17517 17518 17519] [ 5402  5403  5680 ... 12353 12366 12416]\n",
            "[    0     1     2 ... 17517 17518 17519] [ 7272  7752  7798 ... 15719 15766 15910]\n",
            "[    0     1     2 ... 15719 15766 15910] [ 7800  7801  7945 ... 17517 17518 17519]\n",
            "[ 2235  2322  2465 ... 17517 17518 17519] [   0    1    2 ... 6887 6933 6981]\n",
            "[    0     1     2 ... 17517 17518 17519] [2235 2322 2465 ... 8844 8892 8940]\n",
            "[    0     1     2 ... 17517 17518 17519] [ 4493  4877  5068 ... 12687 12943 12983]\n",
            "[    0     1     2 ... 17517 17518 17519] [ 7422  7607  7656 ... 15957 16006 16153]\n",
            "[    0     1     2 ... 15957 16006 16153] [ 7608  7609  7657 ... 17517 17518 17519]\n",
            "[ 1611  1612  1702 ... 17133 17134 17135] [   0    1    2 ... 6411 6552 7367]\n",
            "[    0     1     2 ... 17133 17134 17135] [1611 1612 1702 ... 8817 8867 9036]\n",
            "[    0     1     2 ... 17133 17134 17135] [ 4825  4969  5156 ... 12065 12271 12319]\n",
            "[    0     1     2 ... 17133 17134 17135] [ 6213  6408  6744 ... 15426 15484 15522]\n",
            "[    0     1     2 ... 15426 15484 15522] [ 7512  7800  7896 ... 17133 17134 17135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPx7S11i5a2B",
        "outputId": "85bb5e0b-1b6b-4b34-9413-e06d117c1126"
      },
      "source": [
        "train_df2 = train_df2.reset_index(drop=True)\r\n",
        "train_df3 = train_df3.reset_index(drop=True)\r\n",
        "\r\n",
        "del train_df1['TARGET_day7_cata']\r\n",
        "del train_df2['TARGET_day7_cata']\r\n",
        "del train_df3['TARGET_day7_cata']\r\n",
        "\r\n",
        "X_train_1 = train_df1[train_df1.index.isin(train_index1)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_train_1 = train_df1[train_df1.index.isin(train_index1)]['TARGET_day7']\r\n",
        "X_valid_1 = train_df1[train_df1.index.isin(valid_index1)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_valid_1 = train_df1[train_df1.index.isin(valid_index1)]['TARGET_day7']\r\n",
        "\r\n",
        "X_train_2 = train_df2[train_df2.index.isin(train_index2)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_train_2 = train_df2[train_df2.index.isin(train_index2)]['TARGET_day7']\r\n",
        "X_valid_2 = train_df2[train_df2.index.isin(valid_index2)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_valid_2 = train_df2[train_df2.index.isin(valid_index2)]['TARGET_day7']\r\n",
        "\r\n",
        "X_train_3 = train_df3[train_df3.index.isin(train_index3)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_train_3 = train_df3[train_df3.index.isin(train_index3)]['TARGET_day7']\r\n",
        "X_valid_3 = train_df3[train_df3.index.isin(valid_index3)].drop(columns=['TARGET_day7','TARGET_day8'])\r\n",
        "Y_valid_3 = train_df3[train_df3.index.isin(valid_index3)]['TARGET_day7']\r\n",
        "\r\n",
        "print(X_train_1.shape, Y_train_1.shape, X_valid_1.shape, Y_valid_1.shape)\r\n",
        "print(X_train_2.shape, Y_train_2.shape, X_valid_2.shape, Y_valid_2.shape)\r\n",
        "print(X_train_3.shape, Y_train_3.shape, X_valid_3.shape, Y_valid_3.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14016, 190) (14016,) (3504, 190) (3504,)\n",
            "(14016, 190) (14016,) (3504, 190) (3504,)\n",
            "(13709, 190) (13709,) (3427, 190) (3427,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwsDwh2_3dOB",
        "outputId": "3cc5426a-707b-47ef-9ccd-df1bab291262"
      },
      "source": [
        "Y_valid_1.describe()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3504.000000\n",
              "mean       17.285182\n",
              "std        25.290156\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%        30.523684\n",
              "max        97.849989\n",
              "Name: TARGET_day7, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loVx6eUkx4Hb",
        "outputId": "fc3b011b-c342-4fe8-97e9-74cc3dfde8b1"
      },
      "source": [
        "Y_train_1.describe()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    14016.000000\n",
              "mean        17.276665\n",
              "std         25.265685\n",
              "min          0.000000\n",
              "25%          0.000000\n",
              "50%          0.000000\n",
              "75%         30.590205\n",
              "max         97.666652\n",
              "Name: TARGET_day7, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2wSmOLe171"
      },
      "source": [
        "# 3. Bayesian Optimization & LightGBM\r\n",
        "\r\n",
        "* 제출 시에는 TARGET 1의 3년치 + TARGET 2의 3년치에 대해 모두 Bayesian Optimization & LightGBM 진행\r\n",
        "* 중복을 제외하기 위해 TARGET 1의 첫 연도 데이터에 대해서만 코드 존재"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K2HOoDmQkDt"
      },
      "source": [
        "## TARGET 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0iUpWcEQpu_"
      },
      "source": [
        "#### year 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MwUQBkXz-So",
        "outputId": "03149a8b-865d-409f-ac56-3f77b3dd51dc"
      },
      "source": [
        "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\r\n",
        "\r\n",
        "bounds = {\r\n",
        "    'learning_rate': (0.001, 1.0), # 학습률\r\n",
        "    'num_leaves': (16, 1024), # \r\n",
        "    'feature_fraction' : (0.1, 0.9),\r\n",
        "    'bagging_fraction' : (0.8, 1),\r\n",
        "    'max_depth': (5, 30),   \r\n",
        "    'min_data_in_leaf': (16, 1024)\r\n",
        "}\r\n",
        "\r\n",
        "for q in quantiles:\r\n",
        "  def train_model(learning_rate, num_leaves, bagging_fraction, feature_fraction, \r\n",
        "                      min_data_in_leaf,max_depth,alpha=q):\r\n",
        "    params = {'objective':'quantile','alpha':alpha,'boosting_type':'dart'}\r\n",
        "    params['learning_rate'] = max(min(learning_rate, 1), 0)\r\n",
        "    params[\"num_leaves\"] = int(round(num_leaves))\r\n",
        "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\r\n",
        "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\r\n",
        "    params['max_depth'] = int(round(max_depth))\r\n",
        "    params['min_data_in_leaf'] = int(round(min_data_in_leaf))\r\n",
        "\r\n",
        "    trn_data = lgb.Dataset(X_train_1, Y_train_1)\r\n",
        "    val_data = lgb.Dataset(X_valid_1, Y_valid_1)\r\n",
        "    model = lgb.train(params, trn_data, 500, valid_sets = [trn_data, val_data], verbose_eval=100) # 실제 제출 시에는 500 대신 3000을 사용\r\n",
        "\r\n",
        "    return -model.best_score['valid_1']['quantile']\r\n",
        "      \r\n",
        "  print('#### Predict {}'.format(q))\r\n",
        "  optimizer = BayesianOptimization(f=train_model, pbounds=bounds, random_state=random_seed)\r\n",
        "  optimizer.maximize(init_points=5, n_iter=5) # 실제 제출 시에는 n_iter = 35을 사용\r\n",
        "\r\n",
        "  print('Best Pinball-loss score:', -optimizer.max['target'])\r\n",
        "\r\n",
        "  opt_params_1 = optimizer.max['params']\r\n",
        "  opt_params_1['max_depth']=int(round(opt_params_1['max_depth']))\r\n",
        "  opt_params_1['num_leaves']=int(round(opt_params_1['num_leaves']))\r\n",
        "  opt_params_1['min_data_in_leaf']=int(round(opt_params_1['min_data_in_leaf']))\r\n",
        "  \r\n",
        "  def LGBM_1(q, X_train, Y_train, X_valid, Y_valid, X_test):\r\n",
        "    params = opt_params_1\r\n",
        "    # (a) Modeling  \r\n",
        "    model = LGBMRegressor(objective='quantile', boosting_type='dart', alpha=q,  n_estimators=3000, **params, random_state=random_seed)             \r\n",
        "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \r\n",
        "                eval_set=[(X_valid, Y_valid)], verbose=1000)\r\n",
        "        # (b) Predictions\r\n",
        "    pred = pd.Series(model.predict(X_test).round(2))\r\n",
        "    return pred, model\r\n",
        "\r\n",
        "    # Target 예측\r\n",
        "\r\n",
        "  def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\r\n",
        "    LGBM_models=[]\r\n",
        "    LGBM_actual_pred = pd.DataFrame()\r\n",
        "    pred, model = LGBM_1(q, X_train_1, Y_train_1, X_valid_1, Y_valid_1, test_df)\r\n",
        "    LGBM_models.append(model)\r\n",
        "    LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\r\n",
        "    LGBM_actual_pred.columns=[q]\r\n",
        "    return LGBM_models, LGBM_actual_pred\r\n",
        "\r\n",
        "  models_1, results_1 = train_data(X_train_3, Y_train_3, X_valid_3, Y_valid_3, test_df)\r\n",
        "  # results_1.to_csv(\"/content/drive/MyDrive/DACON/태양광/quantiles/dart/year3/year3_day1_results_{}.csv\".format(q), index=False)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#### Predict 0.1\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 0.737936\tvalid_1's quantile: 1.39787\n",
            "[200]\ttraining's quantile: 0.690109\tvalid_1's quantile: 1.40373\n",
            "[300]\ttraining's quantile: 0.650464\tvalid_1's quantile: 1.3822\n",
            "[400]\ttraining's quantile: 0.622694\tvalid_1's quantile: 1.39858\n",
            "[500]\ttraining's quantile: 0.605644\tvalid_1's quantile: 1.39147\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.391   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.54735\tvalid_1's quantile: 1.42056\n",
            "[200]\ttraining's quantile: 0.484931\tvalid_1's quantile: 1.4123\n",
            "[300]\ttraining's quantile: 0.447579\tvalid_1's quantile: 1.42349\n",
            "[400]\ttraining's quantile: 0.412595\tvalid_1's quantile: 1.42801\n",
            "[500]\ttraining's quantile: 0.398531\tvalid_1's quantile: 1.45445\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.454   \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 22.7    \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.13703\tvalid_1's quantile: 1.26106\n",
            "[200]\ttraining's quantile: 1.06504\tvalid_1's quantile: 1.23047\n",
            "[300]\ttraining's quantile: 1.00831\tvalid_1's quantile: 1.20884\n",
            "[400]\ttraining's quantile: 0.967314\tvalid_1's quantile: 1.21481\n",
            "[500]\ttraining's quantile: 0.940332\tvalid_1's quantile: 1.20903\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-1.209   \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 9.585   \u001b[0m | \u001b[95m 322.7   \u001b[0m | \u001b[95m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.967237\tvalid_1's quantile: 1.22957\n",
            "[200]\ttraining's quantile: 0.89222\tvalid_1's quantile: 1.25528\n",
            "[300]\ttraining's quantile: 0.861508\tvalid_1's quantile: 1.25663\n",
            "[400]\ttraining's quantile: 0.820235\tvalid_1's quantile: 1.25124\n",
            "[500]\ttraining's quantile: 0.792871\tvalid_1's quantile: 1.26135\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.261   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.20255\tvalid_1's quantile: 1.26894\n",
            "[200]\ttraining's quantile: 1.15057\tvalid_1's quantile: 1.24491\n",
            "[300]\ttraining's quantile: 1.10738\tvalid_1's quantile: 1.23401\n",
            "[400]\ttraining's quantile: 1.07764\tvalid_1's quantile: 1.23393\n",
            "[500]\ttraining's quantile: 1.05505\tvalid_1's quantile: 1.22798\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.228   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 17.86   \u001b[0m | \u001b[0m 613.2   \u001b[0m | \u001b[0m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.14922\tvalid_1's quantile: 1.24518\n",
            "[200]\ttraining's quantile: 1.08271\tvalid_1's quantile: 1.23848\n",
            "[300]\ttraining's quantile: 1.03805\tvalid_1's quantile: 1.23984\n",
            "[400]\ttraining's quantile: 1.00445\tvalid_1's quantile: 1.25591\n",
            "[500]\ttraining's quantile: 0.973631\tvalid_1's quantile: 1.25177\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.252   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.937955\tvalid_1's quantile: 1.23629\n",
            "[200]\ttraining's quantile: 0.859885\tvalid_1's quantile: 1.24643\n",
            "[300]\ttraining's quantile: 0.81327\tvalid_1's quantile: 1.25802\n",
            "[400]\ttraining's quantile: 0.780827\tvalid_1's quantile: 1.26099\n",
            "[500]\ttraining's quantile: 0.753712\tvalid_1's quantile: 1.27771\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.278   \u001b[0m | \u001b[0m 0.8627  \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 321.2   \u001b[0m | \u001b[0m 545.4   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.30791\tvalid_1's quantile: 1.33343\n",
            "[200]\ttraining's quantile: 1.24295\tvalid_1's quantile: 1.29534\n",
            "[300]\ttraining's quantile: 1.18363\tvalid_1's quantile: 1.27402\n",
            "[400]\ttraining's quantile: 1.14347\tvalid_1's quantile: 1.25571\n",
            "[500]\ttraining's quantile: 1.1143\tvalid_1's quantile: 1.24008\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.24    \u001b[0m | \u001b[0m 0.9102  \u001b[0m | \u001b[0m 0.2052  \u001b[0m | \u001b[0m 0.05383 \u001b[0m | \u001b[0m 7.608   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 382.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.71166\tvalid_1's quantile: 1.71204\n",
            "[200]\ttraining's quantile: 1.70063\tvalid_1's quantile: 1.70076\n",
            "[300]\ttraining's quantile: 1.6868\tvalid_1's quantile: 1.6859\n",
            "[400]\ttraining's quantile: 1.67245\tvalid_1's quantile: 1.67057\n",
            "[500]\ttraining's quantile: 1.65621\tvalid_1's quantile: 1.65314\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.653   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 591.6   \u001b[0m | \u001b[0m 693.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.71138\tvalid_1's quantile: 1.71212\n",
            "[200]\ttraining's quantile: 1.70057\tvalid_1's quantile: 1.70104\n",
            "[300]\ttraining's quantile: 1.6866\tvalid_1's quantile: 1.68597\n",
            "[400]\ttraining's quantile: 1.67228\tvalid_1's quantile: 1.67016\n",
            "[500]\ttraining's quantile: 1.6566\tvalid_1's quantile: 1.65328\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.653   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 16.0    \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 1.2090296941341279\n",
            "[1000]\tvalid_0's quantile: 1.20042\n",
            "[2000]\tvalid_0's quantile: 1.20692\n",
            "[3000]\tvalid_0's quantile: 1.20756\n",
            "#### Predict 0.2\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.09855\tvalid_1's quantile: 1.9954\n",
            "[200]\ttraining's quantile: 0.929756\tvalid_1's quantile: 1.95995\n",
            "[300]\ttraining's quantile: 0.845375\tvalid_1's quantile: 1.94491\n",
            "[400]\ttraining's quantile: 0.783243\tvalid_1's quantile: 1.94085\n",
            "[500]\ttraining's quantile: 0.754725\tvalid_1's quantile: 1.93663\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.937   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.652503\tvalid_1's quantile: 1.9285\n",
            "[200]\ttraining's quantile: 0.512558\tvalid_1's quantile: 1.87732\n",
            "[300]\ttraining's quantile: 0.461382\tvalid_1's quantile: 1.85994\n",
            "[400]\ttraining's quantile: 0.415095\tvalid_1's quantile: 1.84484\n",
            "[500]\ttraining's quantile: 0.402585\tvalid_1's quantile: 1.84041\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-1.84    \u001b[0m | \u001b[95m 0.8116  \u001b[0m | \u001b[95m 0.7929  \u001b[0m | \u001b[95m 0.6015  \u001b[0m | \u001b[95m 22.7    \u001b[0m | \u001b[95m 36.75   \u001b[0m | \u001b[95m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.80779\tvalid_1's quantile: 1.9704\n",
            "[200]\ttraining's quantile: 1.6612\tvalid_1's quantile: 1.9135\n",
            "[300]\ttraining's quantile: 1.54625\tvalid_1's quantile: 1.89622\n",
            "[400]\ttraining's quantile: 1.45827\tvalid_1's quantile: 1.87493\n",
            "[500]\ttraining's quantile: 1.41296\tvalid_1's quantile: 1.85536\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.855   \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 9.585   \u001b[0m | \u001b[0m 322.7   \u001b[0m | \u001b[0m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.50915\tvalid_1's quantile: 2.02638\n",
            "[200]\ttraining's quantile: 1.38014\tvalid_1's quantile: 2.03374\n",
            "[300]\ttraining's quantile: 1.256\tvalid_1's quantile: 1.97225\n",
            "[400]\ttraining's quantile: 1.18414\tvalid_1's quantile: 1.98802\n",
            "[500]\ttraining's quantile: 1.12776\tvalid_1's quantile: 1.99065\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.991   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.94591\tvalid_1's quantile: 2.00899\n",
            "[200]\ttraining's quantile: 1.82728\tvalid_1's quantile: 1.9461\n",
            "[300]\ttraining's quantile: 1.74382\tvalid_1's quantile: 1.93745\n",
            "[400]\ttraining's quantile: 1.67964\tvalid_1's quantile: 1.90871\n",
            "[500]\ttraining's quantile: 1.63396\tvalid_1's quantile: 1.88038\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.88    \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 17.86   \u001b[0m | \u001b[0m 613.2   \u001b[0m | \u001b[0m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 3.39292\tvalid_1's quantile: 3.39577\n",
            "[200]\ttraining's quantile: 3.35034\tvalid_1's quantile: 3.3485\n",
            "[300]\ttraining's quantile: 3.3015\tvalid_1's quantile: 3.29309\n",
            "[400]\ttraining's quantile: 3.25161\tvalid_1's quantile: 3.24078\n",
            "[500]\ttraining's quantile: 3.19884\tvalid_1's quantile: 3.18993\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.19    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.531514\tvalid_1's quantile: 2.19222\n",
            "[200]\ttraining's quantile: 0.398549\tvalid_1's quantile: 2.07355\n",
            "[300]\ttraining's quantile: 0.354637\tvalid_1's quantile: 2.04282\n",
            "[400]\ttraining's quantile: 0.316333\tvalid_1's quantile: 2.02753\n",
            "[500]\ttraining's quantile: 0.304267\tvalid_1's quantile: 2.00979\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.01    \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 3.40136\tvalid_1's quantile: 3.4015\n",
            "[200]\ttraining's quantile: 3.36201\tvalid_1's quantile: 3.36026\n",
            "[300]\ttraining's quantile: 3.31316\tvalid_1's quantile: 3.3093\n",
            "[400]\ttraining's quantile: 3.26425\tvalid_1's quantile: 3.25828\n",
            "[500]\ttraining's quantile: 3.21244\tvalid_1's quantile: 3.20451\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-3.205   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 60.96   \u001b[0m | \u001b[0m 970.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.67755\tvalid_1's quantile: 2.04152\n",
            "[200]\ttraining's quantile: 1.52089\tvalid_1's quantile: 1.94991\n",
            "[300]\ttraining's quantile: 1.38169\tvalid_1's quantile: 1.94448\n",
            "[400]\ttraining's quantile: 1.29981\tvalid_1's quantile: 1.9158\n",
            "[500]\ttraining's quantile: 1.22373\tvalid_1's quantile: 1.91271\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.913   \u001b[0m | \u001b[0m 0.851   \u001b[0m | \u001b[0m 0.2836  \u001b[0m | \u001b[0m 0.2379  \u001b[0m | \u001b[0m 5.753   \u001b[0m | \u001b[0m 47.94   \u001b[0m | \u001b[0m 1.021e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 1.6292\tvalid_1's quantile: 1.9972\n",
            "[200]\ttraining's quantile: 1.39811\tvalid_1's quantile: 1.94461\n",
            "[300]\ttraining's quantile: 1.31369\tvalid_1's quantile: 1.94545\n",
            "[400]\ttraining's quantile: 1.20352\tvalid_1's quantile: 1.93139\n",
            "[500]\ttraining's quantile: 1.12527\tvalid_1's quantile: 1.918\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.918   \u001b[0m | \u001b[0m 0.8493  \u001b[0m | \u001b[0m 0.7193  \u001b[0m | \u001b[0m 0.5121  \u001b[0m | \u001b[0m 5.135   \u001b[0m | \u001b[0m 20.39   \u001b[0m | \u001b[0m 1.005e+0\u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 1.8404097731023563\n",
            "[1000]\tvalid_0's quantile: 1.85764\n",
            "[2000]\tvalid_0's quantile: 1.85253\n",
            "[3000]\tvalid_0's quantile: 1.84479\n",
            "#### Predict 0.3\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.34649\tvalid_1's quantile: 2.23862\n",
            "[200]\ttraining's quantile: 1.11855\tvalid_1's quantile: 2.19154\n",
            "[300]\ttraining's quantile: 1.00048\tvalid_1's quantile: 2.15165\n",
            "[400]\ttraining's quantile: 0.930907\tvalid_1's quantile: 2.14991\n",
            "[500]\ttraining's quantile: 0.888526\tvalid_1's quantile: 2.14753\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.148   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.708786\tvalid_1's quantile: 2.25464\n",
            "[200]\ttraining's quantile: 0.548424\tvalid_1's quantile: 2.168\n",
            "[300]\ttraining's quantile: 0.474248\tvalid_1's quantile: 2.13829\n",
            "[400]\ttraining's quantile: 0.42051\tvalid_1's quantile: 2.11957\n",
            "[500]\ttraining's quantile: 0.409543\tvalid_1's quantile: 2.1096\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.11    \u001b[0m | \u001b[95m 0.8116  \u001b[0m | \u001b[95m 0.7929  \u001b[0m | \u001b[95m 0.6015  \u001b[0m | \u001b[95m 22.7    \u001b[0m | \u001b[95m 36.75   \u001b[0m | \u001b[95m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.21792\tvalid_1's quantile: 2.35321\n",
            "[200]\ttraining's quantile: 2.019\tvalid_1's quantile: 2.29351\n",
            "[300]\ttraining's quantile: 1.88397\tvalid_1's quantile: 2.26794\n",
            "[400]\ttraining's quantile: 1.78576\tvalid_1's quantile: 2.23156\n",
            "[500]\ttraining's quantile: 1.71087\tvalid_1's quantile: 2.23474\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.235   \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 9.585   \u001b[0m | \u001b[0m 322.7   \u001b[0m | \u001b[0m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.82292\tvalid_1's quantile: 2.36927\n",
            "[200]\ttraining's quantile: 1.63274\tvalid_1's quantile: 2.33136\n",
            "[300]\ttraining's quantile: 1.50203\tvalid_1's quantile: 2.29553\n",
            "[400]\ttraining's quantile: 1.41454\tvalid_1's quantile: 2.3142\n",
            "[500]\ttraining's quantile: 1.34525\tvalid_1's quantile: 2.31295\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.313   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.41162\tvalid_1's quantile: 2.3684\n",
            "[200]\ttraining's quantile: 2.26342\tvalid_1's quantile: 2.3034\n",
            "[300]\ttraining's quantile: 2.15039\tvalid_1's quantile: 2.26604\n",
            "[400]\ttraining's quantile: 2.0732\tvalid_1's quantile: 2.24839\n",
            "[500]\ttraining's quantile: 2.008\tvalid_1's quantile: 2.24282\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.243   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 17.86   \u001b[0m | \u001b[0m 613.2   \u001b[0m | \u001b[0m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 5.04657\tvalid_1's quantile: 5.04529\n",
            "[200]\ttraining's quantile: 4.96136\tvalid_1's quantile: 4.95089\n",
            "[300]\ttraining's quantile: 4.86088\tvalid_1's quantile: 4.84494\n",
            "[400]\ttraining's quantile: 4.76189\tvalid_1's quantile: 4.74853\n",
            "[500]\ttraining's quantile: 4.65684\tvalid_1's quantile: 4.65062\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.651   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.567906\tvalid_1's quantile: 2.38893\n",
            "[200]\ttraining's quantile: 0.395106\tvalid_1's quantile: 2.25486\n",
            "[300]\ttraining's quantile: 0.34397\tvalid_1's quantile: 2.20799\n",
            "[400]\ttraining's quantile: 0.297889\tvalid_1's quantile: 2.18782\n",
            "[500]\ttraining's quantile: 0.285261\tvalid_1's quantile: 2.17577\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.176   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 5.05434\tvalid_1's quantile: 5.05153\n",
            "[200]\ttraining's quantile: 4.97036\tvalid_1's quantile: 4.9626\n",
            "[300]\ttraining's quantile: 4.87017\tvalid_1's quantile: 4.85879\n",
            "[400]\ttraining's quantile: 4.77406\tvalid_1's quantile: 4.7583\n",
            "[500]\ttraining's quantile: 4.66735\tvalid_1's quantile: 4.64854\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.649   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 104.6   \u001b[0m | \u001b[0m 930.9   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.21485\tvalid_1's quantile: 2.44293\n",
            "[200]\ttraining's quantile: 1.99445\tvalid_1's quantile: 2.35437\n",
            "[300]\ttraining's quantile: 1.84902\tvalid_1's quantile: 2.31351\n",
            "[400]\ttraining's quantile: 1.75719\tvalid_1's quantile: 2.29643\n",
            "[500]\ttraining's quantile: 1.68747\tvalid_1's quantile: 2.29628\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.296   \u001b[0m | \u001b[0m 0.8946  \u001b[0m | \u001b[0m 0.4036  \u001b[0m | \u001b[0m 0.1599  \u001b[0m | \u001b[0m 17.1    \u001b[0m | \u001b[0m 302.5   \u001b[0m | \u001b[0m 478.8   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.16648\tvalid_1's quantile: 2.30421\n",
            "[200]\ttraining's quantile: 2.01389\tvalid_1's quantile: 2.27987\n",
            "[300]\ttraining's quantile: 1.87216\tvalid_1's quantile: 2.25483\n",
            "[400]\ttraining's quantile: 1.78482\tvalid_1's quantile: 2.22386\n",
            "[500]\ttraining's quantile: 1.71285\tvalid_1's quantile: 2.2344\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.234   \u001b[0m | \u001b[0m 0.8718  \u001b[0m | \u001b[0m 0.1834  \u001b[0m | \u001b[0m 0.2729  \u001b[0m | \u001b[0m 25.08   \u001b[0m | \u001b[0m 379.5   \u001b[0m | \u001b[0m 490.5   \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 2.1096036987663704\n",
            "[1000]\tvalid_0's quantile: 2.05326\n",
            "[2000]\tvalid_0's quantile: 2.05324\n",
            "[3000]\tvalid_0's quantile: 2.0481\n",
            "#### Predict 0.4\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.42969\tvalid_1's quantile: 2.57163\n",
            "[200]\ttraining's quantile: 1.20049\tvalid_1's quantile: 2.42671\n",
            "[300]\ttraining's quantile: 1.07613\tvalid_1's quantile: 2.39291\n",
            "[400]\ttraining's quantile: 0.995605\tvalid_1's quantile: 2.34677\n",
            "[500]\ttraining's quantile: 0.947333\tvalid_1's quantile: 2.32089\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.321   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.730895\tvalid_1's quantile: 2.34659\n",
            "[200]\ttraining's quantile: 0.560551\tvalid_1's quantile: 2.26442\n",
            "[300]\ttraining's quantile: 0.497123\tvalid_1's quantile: 2.22768\n",
            "[400]\ttraining's quantile: 0.44006\tvalid_1's quantile: 2.21843\n",
            "[500]\ttraining's quantile: 0.423044\tvalid_1's quantile: 2.21216\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.212   \u001b[0m | \u001b[95m 0.8116  \u001b[0m | \u001b[95m 0.7929  \u001b[0m | \u001b[95m 0.6015  \u001b[0m | \u001b[95m 22.7    \u001b[0m | \u001b[95m 36.75   \u001b[0m | \u001b[95m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.4407\tvalid_1's quantile: 2.53652\n",
            "[200]\ttraining's quantile: 2.22676\tvalid_1's quantile: 2.44918\n",
            "[300]\ttraining's quantile: 2.07743\tvalid_1's quantile: 2.44277\n",
            "[400]\ttraining's quantile: 1.95773\tvalid_1's quantile: 2.37731\n",
            "[500]\ttraining's quantile: 1.87597\tvalid_1's quantile: 2.38016\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.38    \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 9.585   \u001b[0m | \u001b[0m 322.7   \u001b[0m | \u001b[0m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.03036\tvalid_1's quantile: 2.45834\n",
            "[200]\ttraining's quantile: 1.78813\tvalid_1's quantile: 2.3709\n",
            "[300]\ttraining's quantile: 1.64633\tvalid_1's quantile: 2.35965\n",
            "[400]\ttraining's quantile: 1.53973\tvalid_1's quantile: 2.35426\n",
            "[500]\ttraining's quantile: 1.46862\tvalid_1's quantile: 2.3495\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.349   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.65389\tvalid_1's quantile: 2.5242\n",
            "[200]\ttraining's quantile: 2.48041\tvalid_1's quantile: 2.3787\n",
            "[300]\ttraining's quantile: 2.35514\tvalid_1's quantile: 2.36155\n",
            "[400]\ttraining's quantile: 2.27028\tvalid_1's quantile: 2.34135\n",
            "[500]\ttraining's quantile: 2.1966\tvalid_1's quantile: 2.36811\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.368   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 17.86   \u001b[0m | \u001b[0m 613.2   \u001b[0m | \u001b[0m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.59898\tvalid_1's quantile: 2.51749\n",
            "[200]\ttraining's quantile: 2.44193\tvalid_1's quantile: 2.45085\n",
            "[300]\ttraining's quantile: 2.33239\tvalid_1's quantile: 2.45258\n",
            "[400]\ttraining's quantile: 2.25943\tvalid_1's quantile: 2.41774\n",
            "[500]\ttraining's quantile: 2.17964\tvalid_1's quantile: 2.4096\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.41    \u001b[0m | \u001b[0m 0.9225  \u001b[0m | \u001b[0m 0.1797  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.598783\tvalid_1's quantile: 2.51453\n",
            "[200]\ttraining's quantile: 0.424115\tvalid_1's quantile: 2.35431\n",
            "[300]\ttraining's quantile: 0.360273\tvalid_1's quantile: 2.31478\n",
            "[400]\ttraining's quantile: 0.313834\tvalid_1's quantile: 2.2908\n",
            "[500]\ttraining's quantile: 0.29766\tvalid_1's quantile: 2.28094\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.281   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 6.68109\tvalid_1's quantile: 6.67353\n",
            "[200]\ttraining's quantile: 6.53955\tvalid_1's quantile: 6.52583\n",
            "[300]\ttraining's quantile: 6.37915\tvalid_1's quantile: 6.35714\n",
            "[400]\ttraining's quantile: 6.22211\tvalid_1's quantile: 6.19326\n",
            "[500]\ttraining's quantile: 6.05035\tvalid_1's quantile: 6.01125\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-6.011   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 114.0   \u001b[0m | \u001b[0m 920.4   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.3509\tvalid_1's quantile: 2.55387\n",
            "[200]\ttraining's quantile: 2.13161\tvalid_1's quantile: 2.47026\n",
            "[300]\ttraining's quantile: 1.98017\tvalid_1's quantile: 2.45402\n",
            "[400]\ttraining's quantile: 1.87858\tvalid_1's quantile: 2.39068\n",
            "[500]\ttraining's quantile: 1.8012\tvalid_1's quantile: 2.39302\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.393   \u001b[0m | \u001b[0m 0.8937  \u001b[0m | \u001b[0m 0.5689  \u001b[0m | \u001b[0m 0.2081  \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 328.9   \u001b[0m | \u001b[0m 462.8   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.32899\tvalid_1's quantile: 2.46602\n",
            "[200]\ttraining's quantile: 2.16978\tvalid_1's quantile: 2.37361\n",
            "[300]\ttraining's quantile: 1.98578\tvalid_1's quantile: 2.3989\n",
            "[400]\ttraining's quantile: 1.90038\tvalid_1's quantile: 2.37318\n",
            "[500]\ttraining's quantile: 1.79184\tvalid_1's quantile: 2.36671\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.367   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5602  \u001b[0m | \u001b[0m 0.4851  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 253.6   \u001b[0m | \u001b[0m 441.6   \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 2.212161224049264\n",
            "[1000]\tvalid_0's quantile: 2.22752\n",
            "[2000]\tvalid_0's quantile: 2.19661\n",
            "[3000]\tvalid_0's quantile: 2.18303\n",
            "#### Predict 0.5\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.46843\tvalid_1's quantile: 2.50927\n",
            "[200]\ttraining's quantile: 1.25404\tvalid_1's quantile: 2.41142\n",
            "[300]\ttraining's quantile: 1.14156\tvalid_1's quantile: 2.38388\n",
            "[400]\ttraining's quantile: 1.06235\tvalid_1's quantile: 2.38533\n",
            "[500]\ttraining's quantile: 1.01498\tvalid_1's quantile: 2.38048\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.38    \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.748651\tvalid_1's quantile: 2.41229\n",
            "[200]\ttraining's quantile: 0.579123\tvalid_1's quantile: 2.30867\n",
            "[300]\ttraining's quantile: 0.524049\tvalid_1's quantile: 2.27354\n",
            "[400]\ttraining's quantile: 0.472239\tvalid_1's quantile: 2.25397\n",
            "[500]\ttraining's quantile: 0.454182\tvalid_1's quantile: 2.25534\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.255   \u001b[0m | \u001b[95m 0.8116  \u001b[0m | \u001b[95m 0.7929  \u001b[0m | \u001b[95m 0.6015  \u001b[0m | \u001b[95m 22.7    \u001b[0m | \u001b[95m 36.75   \u001b[0m | \u001b[95m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.50992\tvalid_1's quantile: 2.49966\n",
            "[200]\ttraining's quantile: 2.27247\tvalid_1's quantile: 2.4\n",
            "[300]\ttraining's quantile: 2.10504\tvalid_1's quantile: 2.37319\n",
            "[400]\ttraining's quantile: 1.99904\tvalid_1's quantile: 2.28062\n",
            "[500]\ttraining's quantile: 1.92059\tvalid_1's quantile: 2.31143\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.311   \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 9.585   \u001b[0m | \u001b[0m 322.7   \u001b[0m | \u001b[0m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.02853\tvalid_1's quantile: 2.24088\n",
            "[200]\ttraining's quantile: 1.80987\tvalid_1's quantile: 2.23536\n",
            "[300]\ttraining's quantile: 1.6763\tvalid_1's quantile: 2.23673\n",
            "[400]\ttraining's quantile: 1.584\tvalid_1's quantile: 2.27701\n",
            "[500]\ttraining's quantile: 1.51256\tvalid_1's quantile: 2.25733\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.257   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.67754\tvalid_1's quantile: 2.40081\n",
            "[200]\ttraining's quantile: 2.51506\tvalid_1's quantile: 2.31942\n",
            "[300]\ttraining's quantile: 2.38874\tvalid_1's quantile: 2.28552\n",
            "[400]\ttraining's quantile: 2.31385\tvalid_1's quantile: 2.24058\n",
            "[500]\ttraining's quantile: 2.23698\tvalid_1's quantile: 2.24462\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m-2.245   \u001b[0m | \u001b[95m 0.8912  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 0.2005  \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 613.2   \u001b[0m | \u001b[95m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.69993\tvalid_1's quantile: 2.47332\n",
            "[200]\ttraining's quantile: 2.51301\tvalid_1's quantile: 2.40723\n",
            "[300]\ttraining's quantile: 2.39597\tvalid_1's quantile: 2.3595\n",
            "[400]\ttraining's quantile: 2.31076\tvalid_1's quantile: 2.3511\n",
            "[500]\ttraining's quantile: 2.22812\tvalid_1's quantile: 2.36654\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.367   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.642336\tvalid_1's quantile: 2.79494\n",
            "[200]\ttraining's quantile: 0.461085\tvalid_1's quantile: 2.59237\n",
            "[300]\ttraining's quantile: 0.399205\tvalid_1's quantile: 2.49693\n",
            "[400]\ttraining's quantile: 0.350595\tvalid_1's quantile: 2.46123\n",
            "[500]\ttraining's quantile: 0.338235\tvalid_1's quantile: 2.43348\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.433   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 8.28766\tvalid_1's quantile: 8.27946\n",
            "[200]\ttraining's quantile: 8.0828\tvalid_1's quantile: 8.06473\n",
            "[300]\ttraining's quantile: 7.84711\tvalid_1's quantile: 7.81459\n",
            "[400]\ttraining's quantile: 7.61642\tvalid_1's quantile: 7.57529\n",
            "[500]\ttraining's quantile: 7.37027\tvalid_1's quantile: 7.31862\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-7.319   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 62.11   \u001b[0m | \u001b[0m 969.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.23914\tvalid_1's quantile: 2.58198\n",
            "[200]\ttraining's quantile: 0.900988\tvalid_1's quantile: 2.48201\n",
            "[300]\ttraining's quantile: 0.760453\tvalid_1's quantile: 2.4444\n",
            "[400]\ttraining's quantile: 0.635162\tvalid_1's quantile: 2.36575\n",
            "[500]\ttraining's quantile: 0.585018\tvalid_1's quantile: 2.36303\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.363   \u001b[0m | \u001b[0m 0.9645  \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 0.1669  \u001b[0m | \u001b[0m 12.85   \u001b[0m | \u001b[0m 22.34   \u001b[0m | \u001b[0m 1e+03   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.802884\tvalid_1's quantile: 2.40828\n",
            "[200]\ttraining's quantile: 0.617283\tvalid_1's quantile: 2.31856\n",
            "[300]\ttraining's quantile: 0.551356\tvalid_1's quantile: 2.30642\n",
            "[400]\ttraining's quantile: 0.500609\tvalid_1's quantile: 2.29262\n",
            "[500]\ttraining's quantile: 0.481305\tvalid_1's quantile: 2.27865\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.279   \u001b[0m | \u001b[0m 0.8178  \u001b[0m | \u001b[0m 0.4625  \u001b[0m | \u001b[0m 0.6961  \u001b[0m | \u001b[0m 14.56   \u001b[0m | \u001b[0m 38.42   \u001b[0m | \u001b[0m 1.018e+0\u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 2.244615698421508\n",
            "[1000]\tvalid_0's quantile: 2.26287\n",
            "[2000]\tvalid_0's quantile: 2.2527\n",
            "[3000]\tvalid_0's quantile: 2.24901\n",
            "#### Predict 0.6\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.39532\tvalid_1's quantile: 2.27348\n",
            "[200]\ttraining's quantile: 1.1985\tvalid_1's quantile: 2.23587\n",
            "[300]\ttraining's quantile: 1.10276\tvalid_1's quantile: 2.1954\n",
            "[400]\ttraining's quantile: 1.03633\tvalid_1's quantile: 2.18922\n",
            "[500]\ttraining's quantile: 0.994957\tvalid_1's quantile: 2.1719\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.172   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.728222\tvalid_1's quantile: 2.42348\n",
            "[200]\ttraining's quantile: 0.589278\tvalid_1's quantile: 2.38664\n",
            "[300]\ttraining's quantile: 0.530391\tvalid_1's quantile: 2.3726\n",
            "[400]\ttraining's quantile: 0.483186\tvalid_1's quantile: 2.35983\n",
            "[500]\ttraining's quantile: 0.468308\tvalid_1's quantile: 2.35491\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.355   \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 22.7    \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.33765\tvalid_1's quantile: 2.32655\n",
            "[200]\ttraining's quantile: 2.12209\tvalid_1's quantile: 2.20647\n",
            "[300]\ttraining's quantile: 1.98726\tvalid_1's quantile: 2.16652\n",
            "[400]\ttraining's quantile: 1.88447\tvalid_1's quantile: 2.08238\n",
            "[500]\ttraining's quantile: 1.80866\tvalid_1's quantile: 2.08137\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-2.081   \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 9.585   \u001b[0m | \u001b[95m 322.7   \u001b[0m | \u001b[95m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.92256\tvalid_1's quantile: 2.11109\n",
            "[200]\ttraining's quantile: 1.73421\tvalid_1's quantile: 2.10076\n",
            "[300]\ttraining's quantile: 1.60185\tvalid_1's quantile: 2.08196\n",
            "[400]\ttraining's quantile: 1.52179\tvalid_1's quantile: 2.07134\n",
            "[500]\ttraining's quantile: 1.46906\tvalid_1's quantile: 2.06138\n",
            "| \u001b[95m 4       \u001b[0m | \u001b[95m-2.061   \u001b[0m | \u001b[95m 0.8864  \u001b[0m | \u001b[95m 0.333   \u001b[0m | \u001b[95m 0.6122  \u001b[0m | \u001b[95m 8.487   \u001b[0m | \u001b[95m 310.5   \u001b[0m | \u001b[95m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.51452\tvalid_1's quantile: 2.16538\n",
            "[200]\ttraining's quantile: 2.35934\tvalid_1's quantile: 2.03776\n",
            "[300]\ttraining's quantile: 2.25305\tvalid_1's quantile: 2.0402\n",
            "[400]\ttraining's quantile: 2.16144\tvalid_1's quantile: 1.9997\n",
            "[500]\ttraining's quantile: 2.10543\tvalid_1's quantile: 1.99396\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m-1.994   \u001b[0m | \u001b[95m 0.8912  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 0.2005  \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 613.2   \u001b[0m | \u001b[95m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.48591\tvalid_1's quantile: 2.03233\n",
            "[200]\ttraining's quantile: 2.33349\tvalid_1's quantile: 2.01327\n",
            "[300]\ttraining's quantile: 2.23981\tvalid_1's quantile: 2.01251\n",
            "[400]\ttraining's quantile: 2.17467\tvalid_1's quantile: 2.00473\n",
            "[500]\ttraining's quantile: 2.10159\tvalid_1's quantile: 1.98794\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m-1.988   \u001b[0m | \u001b[95m 0.8547  \u001b[0m | \u001b[95m 0.1451  \u001b[0m | \u001b[95m 0.8649  \u001b[0m | \u001b[95m 25.32   \u001b[0m | \u001b[95m 1.024e+0\u001b[0m | \u001b[95m 1.021e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 2.49622\tvalid_1's quantile: 2.16986\n",
            "[200]\ttraining's quantile: 2.33266\tvalid_1's quantile: 2.08474\n",
            "[300]\ttraining's quantile: 2.23351\tvalid_1's quantile: 2.03288\n",
            "[400]\ttraining's quantile: 2.15086\tvalid_1's quantile: 2.02538\n",
            "[500]\ttraining's quantile: 2.07968\tvalid_1's quantile: 2.07222\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.072   \u001b[0m | \u001b[0m 0.9042  \u001b[0m | \u001b[0m 0.1286  \u001b[0m | \u001b[0m 0.9046  \u001b[0m | \u001b[0m 24.43   \u001b[0m | \u001b[0m 1.022e+0\u001b[0m | \u001b[0m 1.017e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 9.63014\tvalid_1's quantile: 9.62843\n",
            "[200]\ttraining's quantile: 9.42953\tvalid_1's quantile: 9.42899\n",
            "[300]\ttraining's quantile: 9.13375\tvalid_1's quantile: 9.13294\n",
            "[400]\ttraining's quantile: 8.83669\tvalid_1's quantile: 8.82725\n",
            "[500]\ttraining's quantile: 8.51344\tvalid_1's quantile: 8.49545\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-8.495   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 23.55   \u001b[0m | \u001b[0m 509.6   \u001b[0m | \u001b[0m 199.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.03929\tvalid_1's quantile: 2.09716\n",
            "[200]\ttraining's quantile: 1.86168\tvalid_1's quantile: 2.11411\n",
            "[300]\ttraining's quantile: 1.73935\tvalid_1's quantile: 2.07069\n",
            "[400]\ttraining's quantile: 1.65206\tvalid_1's quantile: 2.08538\n",
            "[500]\ttraining's quantile: 1.59344\tvalid_1's quantile: 2.07808\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.078   \u001b[0m | \u001b[0m 0.9227  \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 0.3992  \u001b[0m | \u001b[0m 9.018   \u001b[0m | \u001b[0m 316.3   \u001b[0m | \u001b[0m 464.4   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.27278\tvalid_1's quantile: 2.02893\n",
            "[200]\ttraining's quantile: 2.10784\tvalid_1's quantile: 2.01435\n",
            "[300]\ttraining's quantile: 2.00359\tvalid_1's quantile: 2.00185\n",
            "[400]\ttraining's quantile: 1.93764\tvalid_1's quantile: 2.01881\n",
            "[500]\ttraining's quantile: 1.86507\tvalid_1's quantile: 1.99425\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.994   \u001b[0m | \u001b[0m 0.9271  \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 0.609   \u001b[0m | \u001b[0m 6.073   \u001b[0m | \u001b[0m 687.6   \u001b[0m | \u001b[0m 19.75   \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 1.9879437932335573\n",
            "[1000]\tvalid_0's quantile: 1.98772\n",
            "[2000]\tvalid_0's quantile: 2.03039\n",
            "[3000]\tvalid_0's quantile: 2.03121\n",
            "#### Predict 0.7\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.26985\tvalid_1's quantile: 1.98209\n",
            "[200]\ttraining's quantile: 1.09395\tvalid_1's quantile: 1.9607\n",
            "[300]\ttraining's quantile: 1.01779\tvalid_1's quantile: 1.97707\n",
            "[400]\ttraining's quantile: 0.961054\tvalid_1's quantile: 1.97389\n",
            "[500]\ttraining's quantile: 0.931248\tvalid_1's quantile: 1.96899\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.969   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.692386\tvalid_1's quantile: 2.3689\n",
            "[200]\ttraining's quantile: 0.575418\tvalid_1's quantile: 2.32057\n",
            "[300]\ttraining's quantile: 0.533429\tvalid_1's quantile: 2.3083\n",
            "[400]\ttraining's quantile: 0.495059\tvalid_1's quantile: 2.30643\n",
            "[500]\ttraining's quantile: 0.48273\tvalid_1's quantile: 2.29639\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.296   \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 22.7    \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.04622\tvalid_1's quantile: 1.87292\n",
            "[200]\ttraining's quantile: 1.83247\tvalid_1's quantile: 1.7521\n",
            "[300]\ttraining's quantile: 1.72707\tvalid_1's quantile: 1.71225\n",
            "[400]\ttraining's quantile: 1.63483\tvalid_1's quantile: 1.63416\n",
            "[500]\ttraining's quantile: 1.5939\tvalid_1's quantile: 1.6577\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-1.658   \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 9.585   \u001b[0m | \u001b[95m 322.7   \u001b[0m | \u001b[95m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.66796\tvalid_1's quantile: 1.70076\n",
            "[200]\ttraining's quantile: 1.5095\tvalid_1's quantile: 1.71488\n",
            "[300]\ttraining's quantile: 1.41848\tvalid_1's quantile: 1.74548\n",
            "[400]\ttraining's quantile: 1.34579\tvalid_1's quantile: 1.73743\n",
            "[500]\ttraining's quantile: 1.3057\tvalid_1's quantile: 1.73515\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.735   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.18397\tvalid_1's quantile: 1.75813\n",
            "[200]\ttraining's quantile: 2.01362\tvalid_1's quantile: 1.6096\n",
            "[300]\ttraining's quantile: 1.93628\tvalid_1's quantile: 1.57961\n",
            "[400]\ttraining's quantile: 1.87121\tvalid_1's quantile: 1.51885\n",
            "[500]\ttraining's quantile: 1.82409\tvalid_1's quantile: 1.54312\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m-1.543   \u001b[0m | \u001b[95m 0.8912  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 0.2005  \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 613.2   \u001b[0m | \u001b[95m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 10.1338\tvalid_1's quantile: 10.4164\n",
            "[200]\ttraining's quantile: 9.67135\tvalid_1's quantile: 10.3442\n",
            "[300]\ttraining's quantile: 9.31853\tvalid_1's quantile: 10.2324\n",
            "[400]\ttraining's quantile: 9.07232\tvalid_1's quantile: 10.1403\n",
            "[500]\ttraining's quantile: 8.70335\tvalid_1's quantile: 9.94462\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-9.945   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.810754\tvalid_1's quantile: 2.77328\n",
            "[200]\ttraining's quantile: 0.583879\tvalid_1's quantile: 2.55451\n",
            "[300]\ttraining's quantile: 0.51987\tvalid_1's quantile: 2.49287\n",
            "[400]\ttraining's quantile: 0.479042\tvalid_1's quantile: 2.46603\n",
            "[500]\ttraining's quantile: 0.463406\tvalid_1's quantile: 2.46318\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.463   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.03672\tvalid_1's quantile: 1.62973\n",
            "[200]\ttraining's quantile: 1.9204\tvalid_1's quantile: 1.56375\n",
            "[300]\ttraining's quantile: 1.84693\tvalid_1's quantile: 1.56422\n",
            "[400]\ttraining's quantile: 1.78817\tvalid_1's quantile: 1.53563\n",
            "[500]\ttraining's quantile: 1.74419\tvalid_1's quantile: 1.56554\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.566   \u001b[0m | \u001b[0m 0.9525  \u001b[0m | \u001b[0m 0.2391  \u001b[0m | \u001b[0m 0.3553  \u001b[0m | \u001b[0m 12.91   \u001b[0m | \u001b[0m 636.4   \u001b[0m | \u001b[0m 67.4    \u001b[0m |\n",
            "[100]\ttraining's quantile: 10.0756\tvalid_1's quantile: 10.1064\n",
            "[200]\ttraining's quantile: 10.1182\tvalid_1's quantile: 10.1433\n",
            "[300]\ttraining's quantile: 9.82171\tvalid_1's quantile: 9.85703\n",
            "[400]\ttraining's quantile: 9.4815\tvalid_1's quantile: 9.53059\n",
            "[500]\ttraining's quantile: 9.09974\tvalid_1's quantile: 9.15538\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-9.155   \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 0.8998  \u001b[0m | \u001b[0m 0.0011  \u001b[0m | \u001b[0m 23.94   \u001b[0m | \u001b[0m 632.4   \u001b[0m | \u001b[0m 31.84   \u001b[0m |\n",
            "[100]\ttraining's quantile: 2.03228\tvalid_1's quantile: 1.63699\n",
            "[200]\ttraining's quantile: 1.92794\tvalid_1's quantile: 1.56701\n",
            "[300]\ttraining's quantile: 1.85391\tvalid_1's quantile: 1.56364\n",
            "[400]\ttraining's quantile: 1.79876\tvalid_1's quantile: 1.53545\n",
            "[500]\ttraining's quantile: 1.7588\tvalid_1's quantile: 1.54408\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.544   \u001b[0m | \u001b[0m 0.9421  \u001b[0m | \u001b[0m 0.316   \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 9.708   \u001b[0m | \u001b[0m 624.4   \u001b[0m | \u001b[0m 64.53   \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 1.5431215523375388\n",
            "[1000]\tvalid_0's quantile: 1.55267\n",
            "[2000]\tvalid_0's quantile: 1.54252\n",
            "[3000]\tvalid_0's quantile: 1.56876\n",
            "#### Predict 0.8\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 1.03141\tvalid_1's quantile: 1.54416\n",
            "[200]\ttraining's quantile: 0.911576\tvalid_1's quantile: 1.54036\n",
            "[300]\ttraining's quantile: 0.855391\tvalid_1's quantile: 1.53765\n",
            "[400]\ttraining's quantile: 0.82239\tvalid_1's quantile: 1.54678\n",
            "[500]\ttraining's quantile: 0.804103\tvalid_1's quantile: 1.56238\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.562   \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.641631\tvalid_1's quantile: 1.89518\n",
            "[200]\ttraining's quantile: 0.553779\tvalid_1's quantile: 1.92125\n",
            "[300]\ttraining's quantile: 0.52191\tvalid_1's quantile: 1.92163\n",
            "[400]\ttraining's quantile: 0.493269\tvalid_1's quantile: 1.94825\n",
            "[500]\ttraining's quantile: 0.480134\tvalid_1's quantile: 1.95858\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.959   \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 22.7    \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.59331\tvalid_1's quantile: 1.44762\n",
            "[200]\ttraining's quantile: 1.38164\tvalid_1's quantile: 1.25326\n",
            "[300]\ttraining's quantile: 1.30997\tvalid_1's quantile: 1.22663\n",
            "[400]\ttraining's quantile: 1.25145\tvalid_1's quantile: 1.1725\n",
            "[500]\ttraining's quantile: 1.22304\tvalid_1's quantile: 1.19804\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-1.198   \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 9.585   \u001b[0m | \u001b[95m 322.7   \u001b[0m | \u001b[95m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.28228\tvalid_1's quantile: 1.27585\n",
            "[200]\ttraining's quantile: 1.19441\tvalid_1's quantile: 1.2394\n",
            "[300]\ttraining's quantile: 1.13757\tvalid_1's quantile: 1.27477\n",
            "[400]\ttraining's quantile: 1.10012\tvalid_1's quantile: 1.29695\n",
            "[500]\ttraining's quantile: 1.07202\tvalid_1's quantile: 1.30843\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.308   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.66913\tvalid_1's quantile: 1.32087\n",
            "[200]\ttraining's quantile: 1.50125\tvalid_1's quantile: 1.13927\n",
            "[300]\ttraining's quantile: 1.44062\tvalid_1's quantile: 1.12591\n",
            "[400]\ttraining's quantile: 1.38825\tvalid_1's quantile: 1.05787\n",
            "[500]\ttraining's quantile: 1.3621\tvalid_1's quantile: 1.06682\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m-1.067   \u001b[0m | \u001b[95m 0.8912  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 0.2005  \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 613.2   \u001b[0m | \u001b[95m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 9.39699\tvalid_1's quantile: 9.41209\n",
            "[200]\ttraining's quantile: 10.1071\tvalid_1's quantile: 10.1226\n",
            "[300]\ttraining's quantile: 9.97986\tvalid_1's quantile: 9.97681\n",
            "[400]\ttraining's quantile: 9.72858\tvalid_1's quantile: 9.7125\n",
            "[500]\ttraining's quantile: 9.41498\tvalid_1's quantile: 9.38493\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-9.385   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.634555\tvalid_1's quantile: 2.04264\n",
            "[200]\ttraining's quantile: 0.531737\tvalid_1's quantile: 1.97996\n",
            "[300]\ttraining's quantile: 0.501729\tvalid_1's quantile: 1.95628\n",
            "[400]\ttraining's quantile: 0.475742\tvalid_1's quantile: 1.97162\n",
            "[500]\ttraining's quantile: 0.465732\tvalid_1's quantile: 1.98074\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.981   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.2161  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 25.65   \u001b[0m | \u001b[0m 36.23   \u001b[0m | \u001b[0m 994.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 9.39807\tvalid_1's quantile: 9.43453\n",
            "[200]\ttraining's quantile: 10.106\tvalid_1's quantile: 10.1502\n",
            "[300]\ttraining's quantile: 9.96202\tvalid_1's quantile: 10.0204\n",
            "[400]\ttraining's quantile: 9.69574\tvalid_1's quantile: 9.7736\n",
            "[500]\ttraining's quantile: 9.37109\tvalid_1's quantile: 9.46521\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-9.465   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 29.51   \u001b[0m | \u001b[0m 583.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.41497\tvalid_1's quantile: 1.25404\n",
            "[200]\ttraining's quantile: 1.31725\tvalid_1's quantile: 1.18508\n",
            "[300]\ttraining's quantile: 1.2658\tvalid_1's quantile: 1.17323\n",
            "[400]\ttraining's quantile: 1.22072\tvalid_1's quantile: 1.14599\n",
            "[500]\ttraining's quantile: 1.19671\tvalid_1's quantile: 1.16097\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.161   \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.3461  \u001b[0m | \u001b[0m 10.99   \u001b[0m | \u001b[0m 371.0   \u001b[0m | \u001b[0m 468.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.52761\tvalid_1's quantile: 1.21051\n",
            "[200]\ttraining's quantile: 1.41547\tvalid_1's quantile: 1.12266\n",
            "[300]\ttraining's quantile: 1.36505\tvalid_1's quantile: 1.10534\n",
            "[400]\ttraining's quantile: 1.31649\tvalid_1's quantile: 1.07155\n",
            "[500]\ttraining's quantile: 1.29372\tvalid_1's quantile: 1.07792\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.078   \u001b[0m | \u001b[0m 0.9007  \u001b[0m | \u001b[0m 0.6927  \u001b[0m | \u001b[0m 0.2965  \u001b[0m | \u001b[0m 16.97   \u001b[0m | \u001b[0m 534.5   \u001b[0m | \u001b[0m 116.8   \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 1.0668201560885318\n",
            "[1000]\tvalid_0's quantile: 1.05946\n",
            "[2000]\tvalid_0's quantile: 1.05126\n",
            "[3000]\tvalid_0's quantile: 1.06004\n",
            "#### Predict 0.9\n",
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | min_da... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "[100]\ttraining's quantile: 0.650672\tvalid_1's quantile: 0.899112\n",
            "[200]\ttraining's quantile: 0.586213\tvalid_1's quantile: 0.883579\n",
            "[300]\ttraining's quantile: 0.567154\tvalid_1's quantile: 0.871623\n",
            "[400]\ttraining's quantile: 0.554478\tvalid_1's quantile: 0.887238\n",
            "[500]\ttraining's quantile: 0.547288\tvalid_1's quantile: 0.891643\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.8916  \u001b[0m | \u001b[0m 0.8749  \u001b[0m | \u001b[0m 0.8606  \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 173.2   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.482448\tvalid_1's quantile: 1.34087\n",
            "[200]\ttraining's quantile: 0.425889\tvalid_1's quantile: 1.43172\n",
            "[300]\ttraining's quantile: 0.403895\tvalid_1's quantile: 1.45491\n",
            "[400]\ttraining's quantile: 0.388372\tvalid_1's quantile: 1.47965\n",
            "[500]\ttraining's quantile: 0.378981\tvalid_1's quantile: 1.49761\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.498   \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 22.7    \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 993.7   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.981354\tvalid_1's quantile: 0.848313\n",
            "[200]\ttraining's quantile: 0.778948\tvalid_1's quantile: 0.663866\n",
            "[300]\ttraining's quantile: 0.73637\tvalid_1's quantile: 0.649262\n",
            "[400]\ttraining's quantile: 0.695154\tvalid_1's quantile: 0.605891\n",
            "[500]\ttraining's quantile: 0.68641\tvalid_1's quantile: 0.613605\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.6136  \u001b[0m | \u001b[95m 0.9665  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 0.1826  \u001b[0m | \u001b[95m 9.585   \u001b[0m | \u001b[95m 322.7   \u001b[0m | \u001b[95m 545.0   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.744155\tvalid_1's quantile: 0.626351\n",
            "[200]\ttraining's quantile: 0.691232\tvalid_1's quantile: 0.603014\n",
            "[300]\ttraining's quantile: 0.667451\tvalid_1's quantile: 0.603905\n",
            "[400]\ttraining's quantile: 0.651174\tvalid_1's quantile: 0.612423\n",
            "[500]\ttraining's quantile: 0.642083\tvalid_1's quantile: 0.613807\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.6138  \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 8.487   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 385.3   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.00515\tvalid_1's quantile: 0.781576\n",
            "[200]\ttraining's quantile: 0.834017\tvalid_1's quantile: 0.626623\n",
            "[300]\ttraining's quantile: 0.796629\tvalid_1's quantile: 0.609473\n",
            "[400]\ttraining's quantile: 0.761068\tvalid_1's quantile: 0.569528\n",
            "[500]\ttraining's quantile: 0.751513\tvalid_1's quantile: 0.571964\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.572   \u001b[0m | \u001b[95m 0.8912  \u001b[0m | \u001b[95m 0.7281  \u001b[0m | \u001b[95m 0.2005  \u001b[0m | \u001b[95m 17.86   \u001b[0m | \u001b[95m 613.2   \u001b[0m | \u001b[95m 62.82   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.933196\tvalid_1's quantile: 0.762801\n",
            "[200]\ttraining's quantile: 0.858186\tvalid_1's quantile: 0.696682\n",
            "[300]\ttraining's quantile: 0.820106\tvalid_1's quantile: 0.6617\n",
            "[400]\ttraining's quantile: 0.803949\tvalid_1's quantile: 0.630914\n",
            "[500]\ttraining's quantile: 0.786711\tvalid_1's quantile: 0.640943\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.6409  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 1.024e+0\u001b[0m |\n",
            "[100]\ttraining's quantile: 0.735393\tvalid_1's quantile: 0.710077\n",
            "[200]\ttraining's quantile: 0.676056\tvalid_1's quantile: 0.696802\n",
            "[300]\ttraining's quantile: 0.654199\tvalid_1's quantile: 0.679497\n",
            "[400]\ttraining's quantile: 0.63968\tvalid_1's quantile: 0.67117\n",
            "[500]\ttraining's quantile: 0.631377\tvalid_1's quantile: 0.676\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.676   \u001b[0m | \u001b[0m 0.8627  \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 321.2   \u001b[0m | \u001b[0m 545.4   \u001b[0m |\n",
            "[100]\ttraining's quantile: 1.83632\tvalid_1's quantile: 1.79321\n",
            "[200]\ttraining's quantile: 1.2092\tvalid_1's quantile: 1.05849\n",
            "[300]\ttraining's quantile: 0.927498\tvalid_1's quantile: 0.799285\n",
            "[400]\ttraining's quantile: 0.812359\tvalid_1's quantile: 0.687272\n",
            "[500]\ttraining's quantile: 0.81633\tvalid_1's quantile: 0.714366\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7144  \u001b[0m | \u001b[0m 0.9102  \u001b[0m | \u001b[0m 0.2052  \u001b[0m | \u001b[0m 0.05383 \u001b[0m | \u001b[0m 7.608   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 382.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.809588\tvalid_1's quantile: 0.778639\n",
            "[200]\ttraining's quantile: 0.722179\tvalid_1's quantile: 0.753697\n",
            "[300]\ttraining's quantile: 0.686826\tvalid_1's quantile: 0.760711\n",
            "[400]\ttraining's quantile: 0.678093\tvalid_1's quantile: 0.737485\n",
            "[500]\ttraining's quantile: 0.676568\tvalid_1's quantile: 0.726357\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.7264  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 403.8   \u001b[0m | \u001b[0m 443.1   \u001b[0m |\n",
            "[100]\ttraining's quantile: 0.848543\tvalid_1's quantile: 0.687532\n",
            "[200]\ttraining's quantile: 0.78876\tvalid_1's quantile: 0.616249\n",
            "[300]\ttraining's quantile: 0.757572\tvalid_1's quantile: 0.604913\n",
            "[400]\ttraining's quantile: 0.741026\tvalid_1's quantile: 0.592062\n",
            "[500]\ttraining's quantile: 0.730334\tvalid_1's quantile: 0.584089\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.5841  \u001b[0m | \u001b[0m 0.897   \u001b[0m | \u001b[0m 0.2554  \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 22.16   \u001b[0m | \u001b[0m 770.9   \u001b[0m | \u001b[0m 93.2    \u001b[0m |\n",
            "=================================================================================================\n",
            "Best Pinball-loss score: 0.571964005733777\n",
            "[1000]\tvalid_0's quantile: 0.56079\n",
            "[2000]\tvalid_0's quantile: 0.556321\n",
            "[3000]\tvalid_0's quantile: 0.560653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR_KsRuAQe6y"
      },
      "source": [
        "# 4. Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXtpCBCnQvMO"
      },
      "source": [
        "## TARGET 1 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i82MGjW861a0"
      },
      "source": [
        "test_files_1  = sorted(glob.glob('/content/drive/MyDrive/DACON/태양광/quantiles/dart/year1/*csv'))\r\n",
        "test_files_2  = sorted(glob.glob('/content/drive/MyDrive/DACON/태양광/quantiles/dart/year2/*csv'))\r\n",
        "test_files_3  = sorted(glob.glob('/content/drive/MyDrive/DACON/태양광/quantiles/dart/year3/*csv'))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhdMVcNWcUVp",
        "outputId": "0cc29f7b-527b-4cad-bc50-661891769c4f"
      },
      "source": [
        "result_1 = []\r\n",
        "result_1 = pd.DataFrame()\r\n",
        "\r\n",
        "for i in range(0,len(test_files_1)):\r\n",
        "  result_1 = pd.concat([result_1, pd.read_csv(test_files_1[i])], axis=1)\r\n",
        "\r\n",
        "result_2 = []\r\n",
        "result_2 = pd.DataFrame()\r\n",
        "\r\n",
        "for i in range(0,len(test_files_2)):\r\n",
        "  result_2 = pd.concat([result_2, pd.read_csv(test_files_2[i])], axis=1)\r\n",
        "\r\n",
        "result_3 = []\r\n",
        "result_3 = pd.DataFrame()\r\n",
        "\r\n",
        "for i in range(0,len(test_files_3)):\r\n",
        "  result_3 = pd.concat([result_3, pd.read_csv(test_files_3[i])], axis=1)\r\n",
        "\r\n",
        "print(result_1.shape, result_2.shape, result_3.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3888, 9) (3888, 9) (3888, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "TKFz77Eicf-C",
        "outputId": "9ea539df-232d-493a-d207-64881bf597af"
      },
      "source": [
        "day_1_res = []\r\n",
        "day_1_res = pd.DataFrame(columns=['0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9'])\r\n",
        "\r\n",
        "for i in result_1.columns:\r\n",
        "  day_1_res[i] = (result_1[i] + result_2[i] + result_3[i]) / 3\r\n",
        "\r\n",
        "def to_zero(x):\r\n",
        "  if x < 0:\r\n",
        "    return 0\r\n",
        "  else:\r\n",
        "    return x\r\n",
        "\r\n",
        "for i in result_1.columns:\r\n",
        "  day_1_res[i] = day_1_res[i].apply(to_zero)\r\n",
        "  \r\n",
        "display(day_1_res)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3883</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3885</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3886</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3887</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3888 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0.1       0.2  0.3  0.4  0.5  0.6  0.7  0.8       0.9\n",
              "0     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.143333\n",
              "1     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.140000\n",
              "2     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.150000\n",
              "3     0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.146667\n",
              "4     0.0  0.013333  0.0  0.0  0.0  0.0  0.0  0.0  0.150000\n",
              "...   ...       ...  ...  ...  ...  ...  ...  ...       ...\n",
              "3883  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.003333\n",
              "3884  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3885  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3886  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3887  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "\n",
              "[3888 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJt54pzcuVr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}